{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA Bind-n-Seq\n",
    "RNA Bind-n-Seq dataset (RBNS) is designed to dissect the sequence and RNA structural\n",
    "preferences of RBPs. An\n",
    "RBP is incubated with a pool of randomized RNAs at several\n",
    "different protein concentrations, typically ranging from low nanomolar to low micromolar. \n",
    "\n",
    "The RNA pool typically\n",
    "consists of random RNAs of length 40 nt flanked by short\n",
    "primers used to add the adapters needed for deep sequencing.\n",
    "\n",
    "RBPbound RNA is reverse-transcribed into cDNA, and barcoded\n",
    "sequencing adapters are added by PCR to produce libraries\n",
    "for deep sequencing. Libraries corresponding to the input RNA\n",
    "pool and to five or more RBP concentrations (including zero\n",
    "RBP concentration as an additional control) are sequenced in\n",
    "a single Illumina HiSeq 2000 lane, typically yielding at least 15–\n",
    "20 million reads per library.\n",
    "\n",
    "Most RBPs bind single-stranded RNA sequence motifs 3–8 nt\n",
    "in length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_RBNS_file(file_name):\n",
    "    \n",
    "    rnas = set()\n",
    "    with open(file_name) as f:\n",
    "        for line in f:\n",
    "            rna = line.strip().split()[0]\n",
    "            rnas.add(rna)\n",
    "    \n",
    "    return rnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['RBP1_input.seq', 'RBP1_5nM.seq', 'RBP1_20nM.seq', 'RBP1_80nM.seq', 'RBP1_320nM.seq', 'RBP1_1300nM.seq']\n",
    "rnas_sets = []\n",
    "\n",
    "for i, file_name in enumerate(files):\n",
    "    rnas_set = parse_RBNS_file(file_name)\n",
    "    rnas_sets.append(rnas_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBP1_input.seq \t 19572050\n",
      "RBP1_5nM.seq \t 9280450\n",
      "RBP1_20nM.seq \t 9807899\n",
      "RBP1_80nM.seq \t 16205127\n",
      "RBP1_320nM.seq \t 14691937\n",
      "RBP1_1300nM.seq \t 17443521\n"
     ]
    }
   ],
   "source": [
    "for i, rna_set in enumerate(rnas_sets):\n",
    "    print(files[i], '\\t', len(rna_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rnas_sets[0].intersection(*rnas_sets[1:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intersection of sequences between different consentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0, j=1, intersection=260\n",
      "i=0, j=2, intersection=263\n",
      "i=0, j=3, intersection=454\n",
      "i=0, j=4, intersection=352\n",
      "i=0, j=5, intersection=434\n",
      "i=1, j=2, intersection=7000\n",
      "i=1, j=3, intersection=1452\n",
      "i=1, j=4, intersection=1705\n",
      "i=1, j=5, intersection=1623\n",
      "i=2, j=3, intersection=2498\n",
      "i=2, j=4, intersection=3659\n",
      "i=2, j=5, intersection=2705\n",
      "i=3, j=4, intersection=496\n",
      "i=3, j=5, intersection=615\n",
      "i=4, j=5, intersection=781\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rnas_sets)-1):\n",
    "    set1 = rnas_sets[i]\n",
    "    for j in range(i+1, len(rnas_sets)):\n",
    "        set2 = rnas_sets[j]\n",
    "        print('i={}, j={}, intersection={}'.format(i, j, len(set1.intersection(set2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 12\n",
    "max_size = 45\n",
    "\n",
    "reverse_compliment_base = {'A': 'U', 'C': 'G', 'T': 'A', 'G': 'C', 'N': 'N'}\n",
    "\n",
    "def reverse_compliment(string):\n",
    "    string = [reverse_compliment_base[base] for base in string[::-1]]\n",
    "    \n",
    "    return ''.join(string)\n",
    "\n",
    "def pad(string, max_size):\n",
    "    string += 'N' * (max_size-len(string))\n",
    "    return string\n",
    "\n",
    "def pad_conv(string, kernel_size):\n",
    "    pad = 'N'*(kernel_size-1)\n",
    "    string = pad + string + pad\n",
    "    return string\n",
    "\n",
    "def read_file_rncmpt(file_path):\n",
    "    sequences = []\n",
    "    with open(file_path) as f:\n",
    "        for line in f:\n",
    "            sequences.append(line.strip())\n",
    "    return sequences\n",
    "\n",
    "def read_file_rbns(path):\n",
    "    sequences = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            sequences.append(line.strip().split())\n",
    "    return sequences\n",
    "\n",
    "\n",
    "def one_hot(string):\n",
    "\n",
    "    dict = {'A': np.array([1, 0, 0, 0]), 'G': np.array([0, 1, 0, 0]),\n",
    "            'C': np.array([0, 0, 1, 0]), 'U': np.array([0, 0, 0, 1]),\n",
    "            'N': np.array([0.25]*4)}\n",
    "    \n",
    "    vec_list = [dict[c].reshape(1, -1) for c in string]\n",
    "    \n",
    "    return np.concatenate(vec_list, axis=0).reshape(len(string), 4, 1)\n",
    "\n",
    "\n",
    "def get_files_list(rbp_ind):\n",
    "    lst = []\n",
    "    for file in os.listdir(PATH):\n",
    "        if file.startswith('RBP' + str(rbp_ind)):\n",
    "            consentration = file.split('_')[1].split('nM')[0]\n",
    "            consentration_val = 0\n",
    "            if consentration != 'input.seq':\n",
    "                consentration_val = int(consentration)\n",
    "                \n",
    "            lst.append((file, consentration_val))\n",
    "    lst.sort(key=lambda x: x[1])\n",
    "    \n",
    "    return [file for file,cons in lst]\n",
    "\n",
    "\n",
    "def get_x(str_dict):\n",
    "    x = [entry['x'] for entry in str_dict]\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_str_dict(seqs_lists):\n",
    "    str_dict = {}\n",
    "    for lst_ind, seqs in enumerate(seqs_lists):\n",
    "        for seq, count in seqs:\n",
    "            if seq in str_dict:\n",
    "                str_dict[seq]['y'][lst_ind] = 1\n",
    "            else:\n",
    "                str_dict[seq] = {'x': one_hot(pad_conv(pad(seq, max_size), kernel_size)), \n",
    "                                 'y': [1 if i == lst_ind else 0 for i in range(len(seqs_lists))]}\n",
    "    return list(str_dict.values())\n",
    "\n",
    "\n",
    "def get_y(str_dict):\n",
    "    y = [entry['y'] for entry in str_dict]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'RBNS/'\n",
    "\n",
    "l = get_files_list(1)\n",
    "\n",
    "seqs_lists = []\n",
    "for file in l:\n",
    "    seqs = read_file_rbns(PATH + file)\n",
    "    rc_seqs = [(reverse_compliment(seq), count) for (seq, count) in seqs]\n",
    "    seqs_lists.append(rc_seqs)\n",
    "\n",
    "str_dict = get_str_dict(seqs_lists)\n",
    "x_train = get_x(str_dict)\n",
    "y_train = get_y(str_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 4, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[1.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [1.  ],\n",
       "        [0.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [1.  ],\n",
       "        [0.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [1.  ],\n",
       "        [0.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[1.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ]],\n",
       "\n",
       "       [[1.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [1.  ],\n",
       "        [0.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [1.  ],\n",
       "        [0.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ]],\n",
       "\n",
       "       [[1.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5996"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/u24870/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/u24870/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 67, 4, 32)         1568      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 67, 4, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8576)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                548928    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 550,886\n",
      "Trainable params: 550,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 6\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (12, 4), strides=(1, 1), padding='same', input_shape=x_train[0].shape))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0005, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/u24870/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/40\n",
      "5996/5996 [==============================] - 1s 232us/step - loss: 1.7935 - acc: 0.1716\n",
      "Epoch 2/40\n",
      "5996/5996 [==============================] - 1s 201us/step - loss: 1.7820 - acc: 0.2033\n",
      "Epoch 3/40\n",
      "5996/5996 [==============================] - 1s 201us/step - loss: 1.7672 - acc: 0.2378\n",
      "Epoch 4/40\n",
      "5996/5996 [==============================] - 1s 203us/step - loss: 1.7538 - acc: 0.2398\n",
      "Epoch 5/40\n",
      "5996/5996 [==============================] - 1s 198us/step - loss: 1.7353 - acc: 0.2575\n",
      "Epoch 6/40\n",
      "5996/5996 [==============================] - 1s 195us/step - loss: 1.7145 - acc: 0.2710\n",
      "Epoch 7/40\n",
      "5996/5996 [==============================] - 1s 199us/step - loss: 1.6908 - acc: 0.2939\n",
      "Epoch 8/40\n",
      "5996/5996 [==============================] - 1s 195us/step - loss: 1.6581 - acc: 0.3122\n",
      "Epoch 9/40\n",
      "5996/5996 [==============================] - 1s 199us/step - loss: 1.6247 - acc: 0.3391\n",
      "Epoch 10/40\n",
      "5996/5996 [==============================] - 1s 199us/step - loss: 1.5916 - acc: 0.3527\n",
      "Epoch 11/40\n",
      "5996/5996 [==============================] - 1s 197us/step - loss: 1.5548 - acc: 0.3726\n",
      "Epoch 12/40\n",
      "5996/5996 [==============================] - 1s 197us/step - loss: 1.5113 - acc: 0.3906\n",
      "Epoch 13/40\n",
      "5996/5996 [==============================] - 1s 201us/step - loss: 1.4763 - acc: 0.4161\n",
      "Epoch 14/40\n",
      "5996/5996 [==============================] - 1s 203us/step - loss: 1.4387 - acc: 0.4455\n",
      "Epoch 15/40\n",
      "5996/5996 [==============================] - 1s 205us/step - loss: 1.4003 - acc: 0.4553\n",
      "Epoch 16/40\n",
      "5996/5996 [==============================] - 1s 202us/step - loss: 1.3538 - acc: 0.4817\n",
      "Epoch 17/40\n",
      "5996/5996 [==============================] - 1s 198us/step - loss: 1.3150 - acc: 0.4988\n",
      "Epoch 18/40\n",
      "5996/5996 [==============================] - 1s 199us/step - loss: 1.2767 - acc: 0.5128\n",
      "Epoch 19/40\n",
      "5996/5996 [==============================] - 1s 197us/step - loss: 1.2271 - acc: 0.5440\n",
      "Epoch 20/40\n",
      "5996/5996 [==============================] - 1s 199us/step - loss: 1.1932 - acc: 0.5597\n",
      "Epoch 21/40\n",
      "5996/5996 [==============================] - 1s 195us/step - loss: 1.1505 - acc: 0.5759\n",
      "Epoch 22/40\n",
      "5996/5996 [==============================] - 1s 197us/step - loss: 1.1138 - acc: 0.5866\n",
      "Epoch 23/40\n",
      "5996/5996 [==============================] - 1s 198us/step - loss: 1.0747 - acc: 0.6039\n",
      "Epoch 24/40\n",
      "5996/5996 [==============================] - 1s 198us/step - loss: 1.0459 - acc: 0.6197\n",
      "Epoch 25/40\n",
      "5996/5996 [==============================] - 1s 199us/step - loss: 0.9953 - acc: 0.6468\n",
      "Epoch 26/40\n",
      "5996/5996 [==============================] - 1s 198us/step - loss: 0.9465 - acc: 0.6609\n",
      "Epoch 27/40\n",
      "5996/5996 [==============================] - 1s 199us/step - loss: 0.9164 - acc: 0.6765\n",
      "Epoch 28/40\n",
      "5996/5996 [==============================] - 1s 198us/step - loss: 0.8778 - acc: 0.6925\n",
      "Epoch 29/40\n",
      "5996/5996 [==============================] - 1s 198us/step - loss: 0.8473 - acc: 0.7043\n",
      "Epoch 30/40\n",
      "5996/5996 [==============================] - 1s 200us/step - loss: 0.8149 - acc: 0.7131\n",
      "Epoch 31/40\n",
      "5996/5996 [==============================] - 1s 199us/step - loss: 0.7700 - acc: 0.7315\n",
      "Epoch 32/40\n",
      "5996/5996 [==============================] - 1s 197us/step - loss: 0.7411 - acc: 0.7482\n",
      "Epoch 33/40\n",
      "5996/5996 [==============================] - 1s 201us/step - loss: 0.7004 - acc: 0.7637\n",
      "Epoch 34/40\n",
      "5996/5996 [==============================] - 1s 200us/step - loss: 0.6665 - acc: 0.7822\n",
      "Epoch 35/40\n",
      "5996/5996 [==============================] - 1s 201us/step - loss: 0.6437 - acc: 0.7829\n",
      "Epoch 36/40\n",
      "5996/5996 [==============================] - 1s 198us/step - loss: 0.6033 - acc: 0.7980\n",
      "Epoch 37/40\n",
      "5996/5996 [==============================] - 1s 198us/step - loss: 0.5857 - acc: 0.8050\n",
      "Epoch 38/40\n",
      "5996/5996 [==============================] - 1s 200us/step - loss: 0.5576 - acc: 0.8212\n",
      "Epoch 39/40\n",
      "5996/5996 [==============================] - 1s 200us/step - loss: 0.5248 - acc: 0.8269\n",
      "Epoch 40/40\n",
      "5996/5996 [==============================] - 1s 200us/step - loss: 0.5043 - acc: 0.8386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc23f6cbc88>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(x_train), np.array(y_train),\n",
    "              batch_size=batch_size,\n",
    "              epochs=40,\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240036, 67, 4, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'RNCMPT/RBP1_RNCMPT.sorted'\n",
    "seqs = read_file_rncmpt(file_path)\n",
    "seqs = [pad_conv(pad(seq, max_size), kernel_size) for seq in seqs]\n",
    "\n",
    "x_test = np.array([one_hot(seq) for seq in seqs])\n",
    "y_test = [int(x) for x in np.append(np.ones(1000), np.zeros(len(x_test)-1000), axis=0)]\n",
    "\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240036"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.6624413e-07, 4.4703484e-06, 1.7881393e-07, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_scores = [np.dot(y, np.array([1, 1, 236, 1, 1, 1])) for y in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.723668098449707e-05"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc1dfe49c18>]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(y_pred_sums)), y_pred_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_y_pred = list(zip(seqs, y_pred_scores, list(range(len(seqs)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_y_pred_sorted = sorted(x_test_y_pred, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "x_test_y_pred_tagged = [(seq, tag, ind) for (seq, score, ind),tag in zip(x_test_y_pred_sorted, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_y_pred_tagged = sorted(x_test_y_pred_tagged, key=lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([tag for (seq, tag, ind) in x_test_y_pred_tagged[:1000]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel, 2019 update 2)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_2019u2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
