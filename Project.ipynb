{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA Bind-n-Seq\n",
    "RNA Bind-n-Seq dataset (RBNS) is designed to dissect the sequence and RNA structural\n",
    "preferences of RBPs. An\n",
    "RBP is incubated with a pool of randomized RNAs at several\n",
    "different protein concentrations, typically ranging from low nanomolar to low micromolar. \n",
    "\n",
    "The RNA pool typically\n",
    "consists of random RNAs of length 40 nt flanked by short\n",
    "primers used to add the adapters needed for deep sequencing.\n",
    "\n",
    "RBPbound RNA is reverse-transcribed into cDNA, and barcoded\n",
    "sequencing adapters are added by PCR to produce libraries\n",
    "for deep sequencing. Libraries corresponding to the input RNA\n",
    "pool and to five or more RBP concentrations (including zero\n",
    "RBP concentration as an additional control) are sequenced in\n",
    "a single Illumina HiSeq 2000 lane, typically yielding at least 15–\n",
    "20 million reads per library.\n",
    "\n",
    "Most RBPs bind single-stranded RNA sequence motifs 3–8 nt\n",
    "in length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_list(rbp_ind):\n",
    "    \n",
    "    lst = []\n",
    "    for file in os.listdir(PATH):\n",
    "        if file.startswith('RBP' + str(rbp_ind) + '_'):\n",
    "            \n",
    "            consentration = file.split('_')[1].split('nM')[0]\n",
    "            consentration_val = 0\n",
    "            if consentration != 'input.seq':\n",
    "                consentration_val = int(consentration)\n",
    "                \n",
    "            lst.append((file, consentration_val))\n",
    "            \n",
    "    lst.sort(key=lambda x: x[1])\n",
    "    print(lst)\n",
    "    return [file for file,cons in lst]\n",
    "\n",
    "\n",
    "def read_file_rbns(path):\n",
    "    sequences = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            sequences.append(line.strip().split())\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('RBP1_input.seq', 0), ('RBP1_5nM.seq', 5), ('RBP1_20nM.seq', 20), ('RBP1_80nM.seq', 80), ('RBP1_320nM.seq', 320), ('RBP1_1300nM.seq', 1300)]\n"
     ]
    }
   ],
   "source": [
    "PATH = 'RBNS_example/'\n",
    "rbp_ind = 1\n",
    "\n",
    "l = get_files_list(rbp_ind)\n",
    "\n",
    "rnas_sets = []\n",
    "\n",
    "for file in l:\n",
    "    seqs = read_file_rbns(PATH + file)\n",
    "    rnas_set = set([seq for (seq, count) in seqs])\n",
    "    rnas_sets.append(rnas_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBP1_input.seq \t 1000\n",
      "RBP1_5nM.seq \t 1000\n",
      "RBP1_20nM.seq \t 1000\n",
      "RBP1_80nM.seq \t 1000\n",
      "RBP1_320nM.seq \t 1000\n",
      "RBP1_1300nM.seq \t 1000\n"
     ]
    }
   ],
   "source": [
    "for i, rna_set in enumerate(rnas_sets):\n",
    "    print(l[i], '\\t', len(rna_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rnas_sets[0].intersection(*rnas_sets[1:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intersection of sequences between different consentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0, j=1, intersection=0\n",
      "i=0, j=2, intersection=0\n",
      "i=0, j=3, intersection=0\n",
      "i=0, j=4, intersection=0\n",
      "i=0, j=5, intersection=0\n",
      "i=1, j=2, intersection=2\n",
      "i=1, j=3, intersection=0\n",
      "i=1, j=4, intersection=0\n",
      "i=1, j=5, intersection=0\n",
      "i=2, j=3, intersection=1\n",
      "i=2, j=4, intersection=0\n",
      "i=2, j=5, intersection=0\n",
      "i=3, j=4, intersection=0\n",
      "i=3, j=5, intersection=1\n",
      "i=4, j=5, intersection=0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rnas_sets)-1):\n",
    "    set1 = rnas_sets[i]\n",
    "    for j in range(i+1, len(rnas_sets)):\n",
    "        set2 = rnas_sets[j]\n",
    "        print('i={}, j={}, intersection={}'.format(i, j, len(set1.intersection(set2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 12\n",
    "max_size = 45\n",
    "\n",
    "reverse_compliment_base = {'A': 'U', 'C': 'G', 'T': 'A', 'G': 'C', 'N': 'N'}\n",
    "#reverse_compliment_base = {'A': 'A', 'C': 'C', 'T': 'U', 'G': 'G', 'N': 'N'}\n",
    "\n",
    "def reverse_compliment(string):\n",
    "    string = [reverse_compliment_base[base] for base in string[::-1]]\n",
    "    #string = [reverse_compliment_base[base] for base in string]\n",
    "    \n",
    "    return ''.join(string)\n",
    "\n",
    "def pad(string, max_size):\n",
    "    string += 'N' * (max_size-len(string))\n",
    "    return string\n",
    "\n",
    "def pad_conv(string, kernel_size):\n",
    "    pad = 'N'*(kernel_size-1)\n",
    "    string = pad + string + pad\n",
    "    return string\n",
    "\n",
    "def read_file_rncmpt(file_path):\n",
    "    sequences = []\n",
    "    with open(file_path) as f:\n",
    "        for line in f:\n",
    "            sequences.append(line.strip())\n",
    "    return sequences\n",
    "\n",
    "\n",
    "def one_hot(string):\n",
    "\n",
    "    dict = {'A': np.array([1, 0, 0, 0]), 'G': np.array([0, 1, 0, 0]),\n",
    "            'C': np.array([0, 0, 1, 0]), 'U': np.array([0, 0, 0, 1]),\n",
    "            'N': np.array([0.25]*4)}\n",
    "    \n",
    "    vec_list = [dict[c].reshape(1, -1) for c in string]\n",
    "    \n",
    "    return np.concatenate(vec_list, axis=0).reshape(len(string), 4, 1)\n",
    "\n",
    "\n",
    "def get_x(str_dict):\n",
    "    x = [entry['x'] for entry in str_dict]\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_str_dict(seqs_lists):\n",
    "    str_dict = {}\n",
    "    for lst_ind, seqs in enumerate(seqs_lists):\n",
    "        for seq, count in seqs:\n",
    "            if seq in str_dict:\n",
    "                str_dict[seq]['y'][lst_ind] = 1\n",
    "            else:\n",
    "                str_dict[seq] = {'x': one_hot(pad_conv(pad(seq, max_size), kernel_size)), \n",
    "                                 'y': [1 if i == lst_ind else 0 for i in range(len(seqs_lists))]}\n",
    "    return list(str_dict.values())\n",
    "\n",
    "\n",
    "def get_y(str_dict):\n",
    "    y = [entry['y'] for entry in str_dict]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_lists = []\n",
    "\n",
    "for file in l:\n",
    "    seqs = read_file_rbns(PATH + file)\n",
    "    rc_seqs = [(reverse_compliment(seq), count) for (seq, count) in seqs]\n",
    "    seqs_lists.append(rc_seqs)\n",
    "\n",
    "str_dict = get_str_dict(seqs_lists)\n",
    "x_train = get_x(str_dict)\n",
    "y_train = get_y(str_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 4, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[1.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [1.  ],\n",
       "        [0.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [1.  ],\n",
       "        [0.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [1.  ],\n",
       "        [0.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[1.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ]],\n",
       "\n",
       "       [[1.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [1.  ],\n",
       "        [0.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [1.  ],\n",
       "        [0.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ]],\n",
       "\n",
       "       [[1.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ]],\n",
       "\n",
       "       [[0.  ],\n",
       "        [0.  ],\n",
       "        [1.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]],\n",
       "\n",
       "       [[0.25],\n",
       "        [0.25],\n",
       "        [0.25],\n",
       "        [0.25]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5996"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/u24870/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/u24870/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 67, 4, 32)         1568      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 67, 4, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 352)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                22592     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 24,550\n",
      "Trainable params: 24,550\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 6\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (12, 4), strides=(1, 1), padding='same', input_shape=x_train[0].shape))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(6, 4)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0005, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/u24870/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/40\n",
      "5996/5996 [==============================] - 1s 224us/step - loss: 1.7952 - acc: 0.1606\n",
      "Epoch 2/40\n",
      "5996/5996 [==============================] - 1s 202us/step - loss: 1.7936 - acc: 0.1733\n",
      "Epoch 3/40\n",
      "5996/5996 [==============================] - 1s 200us/step - loss: 1.7920 - acc: 0.1806\n",
      "Epoch 4/40\n",
      "5996/5996 [==============================] - 1s 197us/step - loss: 1.7910 - acc: 0.1835\n",
      "Epoch 5/40\n",
      "5996/5996 [==============================] - 1s 209us/step - loss: 1.7881 - acc: 0.1935\n",
      "Epoch 6/40\n",
      "5996/5996 [==============================] - 1s 205us/step - loss: 1.7866 - acc: 0.2063\n",
      "Epoch 7/40\n",
      "5996/5996 [==============================] - 1s 197us/step - loss: 1.7835 - acc: 0.2100\n",
      "Epoch 8/40\n",
      "5996/5996 [==============================] - 1s 201us/step - loss: 1.7804 - acc: 0.2133\n",
      "Epoch 9/40\n",
      "5996/5996 [==============================] - 1s 203us/step - loss: 1.7751 - acc: 0.2243\n",
      "Epoch 10/40\n",
      "5996/5996 [==============================] - 1s 197us/step - loss: 1.7719 - acc: 0.2270\n",
      "Epoch 11/40\n",
      "5996/5996 [==============================] - 1s 202us/step - loss: 1.7651 - acc: 0.2268\n",
      "Epoch 12/40\n",
      "5996/5996 [==============================] - 1s 200us/step - loss: 1.7608 - acc: 0.2463\n",
      "Epoch 13/40\n",
      "5996/5996 [==============================] - 1s 198us/step - loss: 1.7543 - acc: 0.2455\n",
      "Epoch 14/40\n",
      "5996/5996 [==============================] - 1s 199us/step - loss: 1.7482 - acc: 0.2445\n",
      "Epoch 15/40\n",
      "5996/5996 [==============================] - 1s 204us/step - loss: 1.7415 - acc: 0.2583\n",
      "Epoch 16/40\n",
      "5996/5996 [==============================] - 1s 202us/step - loss: 1.7347 - acc: 0.2577\n",
      "Epoch 17/40\n",
      "5996/5996 [==============================] - 1s 201us/step - loss: 1.7278 - acc: 0.2598\n",
      "Epoch 18/40\n",
      "5996/5996 [==============================] - 1s 197us/step - loss: 1.7205 - acc: 0.2698\n",
      "Epoch 19/40\n",
      "5996/5996 [==============================] - 1s 198us/step - loss: 1.7140 - acc: 0.2725\n",
      "Epoch 20/40\n",
      "5996/5996 [==============================] - 1s 196us/step - loss: 1.7095 - acc: 0.2799\n",
      "Epoch 21/40\n",
      "5996/5996 [==============================] - 1s 200us/step - loss: 1.6962 - acc: 0.2889\n",
      "Epoch 22/40\n",
      "5996/5996 [==============================] - 1s 202us/step - loss: 1.6930 - acc: 0.2892\n",
      "Epoch 23/40\n",
      "5996/5996 [==============================] - 1s 196us/step - loss: 1.6896 - acc: 0.2984\n",
      "Epoch 24/40\n",
      "5996/5996 [==============================] - 1s 201us/step - loss: 1.6815 - acc: 0.2955\n",
      "Epoch 25/40\n",
      "5996/5996 [==============================] - 1s 200us/step - loss: 1.6744 - acc: 0.3050\n",
      "Epoch 26/40\n",
      "5996/5996 [==============================] - 1s 199us/step - loss: 1.6671 - acc: 0.3070\n",
      "Epoch 27/40\n",
      "5996/5996 [==============================] - 1s 196us/step - loss: 1.6643 - acc: 0.3054\n",
      "Epoch 28/40\n",
      "5996/5996 [==============================] - 1s 202us/step - loss: 1.6535 - acc: 0.3154\n",
      "Epoch 29/40\n",
      "5996/5996 [==============================] - 1s 201us/step - loss: 1.6503 - acc: 0.3179\n",
      "Epoch 30/40\n",
      "5996/5996 [==============================] - 1s 193us/step - loss: 1.6487 - acc: 0.3224\n",
      "Epoch 31/40\n",
      "5996/5996 [==============================] - 1s 198us/step - loss: 1.6423 - acc: 0.3204\n",
      "Epoch 32/40\n",
      "5996/5996 [==============================] - 1s 198us/step - loss: 1.6389 - acc: 0.3331\n",
      "Epoch 33/40\n",
      "5996/5996 [==============================] - 1s 197us/step - loss: 1.6328 - acc: 0.3326\n",
      "Epoch 34/40\n",
      "5996/5996 [==============================] - 1s 201us/step - loss: 1.6265 - acc: 0.3302\n",
      "Epoch 35/40\n",
      "5996/5996 [==============================] - 1s 200us/step - loss: 1.6204 - acc: 0.3347\n",
      "Epoch 36/40\n",
      "5996/5996 [==============================] - 1s 199us/step - loss: 1.6190 - acc: 0.3407\n",
      "Epoch 37/40\n",
      "5996/5996 [==============================] - 1s 198us/step - loss: 1.6157 - acc: 0.3431\n",
      "Epoch 38/40\n",
      "5996/5996 [==============================] - 1s 198us/step - loss: 1.6108 - acc: 0.3421\n",
      "Epoch 39/40\n",
      "5996/5996 [==============================] - 1s 200us/step - loss: 1.6035 - acc: 0.3519\n",
      "Epoch 40/40\n",
      "5996/5996 [==============================] - 1s 195us/step - loss: 1.6073 - acc: 0.3516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f24e55fa128>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(x_train), np.array(y_train),\n",
    "              batch_size=batch_size,\n",
    "              epochs=40,\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240036, 67, 4, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'RNCMPT/RBP1_RNCMPT.sorted'\n",
    "seqs = read_file_rncmpt(file_path)\n",
    "seqs = [pad_conv(pad(seq, max_size), kernel_size) for seq in seqs]\n",
    "\n",
    "x_test = np.array([one_hot(seq) for seq in seqs])\n",
    "y_test = [int(x) for x in np.append(np.ones(1000), np.zeros(len(x_test)-1000), axis=0)]\n",
    "\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240036"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04016066, 0.00632429, 0.00990674, 0.01556998, 0.0268234 ,\n",
       "       0.03622642], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_scores = [np.dot(y, np.array([1, 1, 1, 1, 1, 1])) for y in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1350114941596985"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f24e4aa79b0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(range(len(y_pred_scores)), y_pred_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_y_pred = list(zip(seqs, y_pred_scores, list(range(len(seqs)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_y_pred_sorted = sorted(x_test_y_pred, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "x_test_y_pred_tagged = [(seq, tag, ind) for (seq, score, ind),tag in zip(x_test_y_pred_sorted, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_y_pred_tagged = sorted(x_test_y_pred_tagged, key=lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positives 4\n"
     ]
    }
   ],
   "source": [
    "positives = sum([tag for (seq, tag, ind) in x_test_y_pred_tagged[:1000]])\n",
    "print('positives', positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_precision 0.004165377593360996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "avg_precision = average_precision_score(y_test, [tag for (seq, tag, ind) in x_test_y_pred_tagged])\n",
    "print('avg_precision', avg_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand\n",
    "\n",
    "def ran_avg_precision():\n",
    "    random_pred = [int(x) for x in np.append(np.ones(1000), np.zeros(len(x_test)-1000), axis=0)]\n",
    "    rand.shuffle(random_pred)\n",
    "    print([sum(rand.sample(random_pred, len(random_pred))[:1000]) for i in range(100)])\n",
    "    average_precision_score(y_test, random_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel, 2019 update 2)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_2019u2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
